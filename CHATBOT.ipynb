{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CHATBOT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v4nO5m545xuy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db8f4b49-5e7b-46e7-f672-0380b7fc7cb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "import string\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f=open('chatbot.txt','r',errors = 'ignore')\n",
        "raw_doc=f.read()\n",
        "raw_doc=raw_doc.lower() #Converts text to lowercase\n",
        "nltk.download('punkt') #Using the Punkt tokenizer\n",
        "nltk.download('wordnet') #Using the WordNet dictionary\n",
        "sent_tokens = nltk.sent_tokenize(raw_doc) #Converts doc to list of sentences \n",
        "word_tokens = nltk.word_tokenize(raw_doc) #Converts doc to list of words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCMdPqtD55yK",
        "outputId": "2383ce0f-c23b-48ce-b3b6-e19035e8ab66"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokens[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkWARFJK6hRn",
        "outputId": "27cbedd6-2d66-4e6f-8dc3-3bcc90600cb2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['điểm thi ngành cơ điện tử: khối a 25đ, khối a1 24đ, khối d 23đ.',\n",
              " 'điểm thi ngành ô tô: khối a 27đ, khối a1 26đ, khối d 25đ.']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokens[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4o9MP_L6lSK",
        "outputId": "5e70b285-7cf0-4f47-c733-69828b2d792c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['điểm', 'thi']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "#WordNet is a semantically-oriented dictionary of English included in NLTK.\n",
        "def LemTokens(tokens):\n",
        "    return [lemmer.lemmatize(token) for token in tokens]\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "def LemNormalize(text):\n",
        "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
      ],
      "metadata": {
        "id": "qY92qycc6pgj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GREET_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\")\n",
        "GREET_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
        "def greet(sentence):\n",
        " \n",
        "    for word in sentence.split():\n",
        "        if word.lower() in GREET_INPUTS:\n",
        "            return random.choice(GREET_RESPONSES)"
      ],
      "metadata": {
        "id": "hVo0BJI36u7O"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "BGb06oYW6yGo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def response(user_response):\n",
        "  robo1_response=''\n",
        "  TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
        "  tfidf = TfidfVec.fit_transform(sent_tokens)\n",
        "  vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "  idx=vals.argsort()[0][-2]\n",
        "  flat = vals.flatten()\n",
        "  flat.sort()\n",
        "  req_tfidf = flat[-2]\n",
        "  if(req_tfidf==0):\n",
        "    robo1_response=robo1_response+\"I am sorry! I don't understand you\"\n",
        "    return robo1_response\n",
        "  else:\n",
        "    robo1_response = robo1_response+sent_tokens[idx]\n",
        "    return robo1_response"
      ],
      "metadata": {
        "id": "M9Z_ybHj61Gh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flag=True\n",
        "print(\"BOT: Chào mừng bạn đã đến với kênh tư vấn tuyển sinh của trường đại học Sư phạm kỹ thuật TPHCM ! Tôi có thể giúp gì cho bạn nào ! Nếu bạn muốn kết thúc câu hỏi thì hãy đánh ký tự bye\")\n",
        "while(flag==True):\n",
        "    user_response = input()\n",
        "    user_response=user_response.lower()\n",
        "    if(user_response!='bye'):\n",
        "        if(user_response=='thanks' or user_response=='thank you' ):\n",
        "            flag=False\n",
        "            print(\"BOT: You are welcome..\")\n",
        "        else:\n",
        "            if(greet(user_response)!=None):\n",
        "                print(\"BOT: \"+greet(user_response))\n",
        "            else:\n",
        "                sent_tokens.append(user_response)\n",
        "                word_tokens=word_tokens+nltk.word_tokenize(user_response)\n",
        "                final_words=list(set(word_tokens))\n",
        "                print(\"BOT: \",end=\"\")\n",
        "                print(response(user_response))\n",
        "                sent_tokens.remove(user_response)\n",
        "    else:\n",
        "        flag=False\n",
        "        print(\"BOT: Goodbye! Take care <3 \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSy-h29063qk",
        "outputId": "8d434f63-5aec-41f6-ee76-51f43b8f452c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOT: Chào mừng bạn đã đến với kênh tư vấn tuyển sinh của trường đại học Sư phạm kỹ thuật TPHCM ! Tôi có thể giúp gì cho bạn nào ! Nếu bạn muốn kết thúc câu hỏi thì hãy đánh ký tự bye\n",
            "hi\n",
            "BOT: hi\n",
            "cho mình biết điểm thi ngành cơ điện tử\n",
            "BOT: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "điểm thi ngành cơ điện tử: khối a 25đ, khối a1 24đ, khối d 23đ.\n",
            "cho mình biết điểm thi ngành công nghệ thông tin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BOT: điểm thi ngành công nghệ thông tin: khối a 27,5đ, khối a1 26,5 điểm, khối d 25đ.\n",
            "cho mình biết điểm thi ngành kỹ thuật máy tính\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BOT: điểm thi ngành kỹ thuật máy tính: khối a 24đ, khối a1 23,5 điểm, khối d 21đ.\n",
            "phương thức tuyển sinh\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BOT: phương thức tuyển sinh:\n",
            "phương thức 1: xét tuyển học bạ thpt, xét tuyển dựa vào điểm trung bình học bạ 5 học kỳ (trừ học kỳ 2 lớp 12) của từng môn theo tổ hợp từ 7.0 trở lên (có 3 môn) vào học hệ chất lượng cao hoặc đại trà\n",
            "phương thức 2: xét tuyển thí sinh theo kết quả điểm thi tốt nghiệp thpt năm 2022 theo các tổ hợp môn xét tuyển từng ngành học, thời gian nhận hồ sơ và công bố kết quả theo quy định của bộ gd-đt\n",
            "phương thức 3: xét tuyển thí sinh theo kết quả kỳ thi đánh giá năng lực của đh quốc gia tp.hcm, điều kiện xét tuyển: điểm bài thi đánh giá năng lực đh quốc gia tp.hcm năm 2022 từ 700 điểm trở lên\n",
            "phương thức 4: xét tuyển thẳng, ưu tiên xét tuyển thẳng, xét tuyển thẳng theo quy định của bộ gd-đt, ưu tiên xét tuyển thẳng theo quy định của trường (thí sinh giải 1, 2, 3 cấp tỉnh, giải khuyến khích học sinh giỏi cấp quốc gia hoặc giải 4 cuộc thi khoa học kỹ thuật cấp quốc gia; học sinh giỏi trường chuyên - tốp 200; xét điểm ielts quốc tế; điểm sat quốc tế; trường thpt liên kết do hiệu trưởng giới thiệu).\n",
            "thông tin về trường\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BOT: thông tin về trường: trường đại học sư phạm kỹ thuật thành phố hồ chí minh (tiếng anh: ho chi minh city university of technology and education) là một trường đại học đa ngành tại việt nam, với thế mạnh về đào tạo kỹ thuật, được đánh giá là một trong những trường đại học kỹ thuật hàng đầu về đào tạo khối ngành kỹ thuật tại miền nam,\n",
            "trường là một trong 6 đại học sư phạm kỹ thuật của cả nước – đào tạo kỹ thuật lấy ứng dụng làm trọng tâm để giảng dạy, có chức năng đào tạo kỹ sư công nghệ và giáo viên kỹ thuật, đồng thời cũng là trung tâm nghiên cứu khoa học và chuyển giao công nghệ của miền nam việt nam.\n",
            "các khoa của trường\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BOT: các khoa của trường: khoa lý luận chính trị\n",
            "khoa khoa học ứng dụng\n",
            "khoa cơ khí chế tạo máy\n",
            "khoa điện - điện tử\n",
            "khoa cơ khí động lực\n",
            "khoa kinh tế\n",
            "khoa công nghệ thông tin\n",
            "khoa in và truyền thông\n",
            "khoa công nghệ may và thời trang\n",
            "khoa công nghệ hóa học và thực phẩm\n",
            "khoa xây dựng\n",
            "khoa ngoại ngữ\n",
            "khoa đào tạo chất lượng cao\n",
            "viện sư phạm kỹ thuật\n",
            "trường trung học kỹ thuật thực hành.\n",
            "major of university\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOT: major of university: đào tạo kỹ sư (4 năm):công nghệ kỹ thuật điện, điện tử (aun-qa)\n",
            "công nghệ chế tạo máy\n",
            "công nghệ kỹ thuật cơ điện tử (aun-qa)\n",
            "công nghệ kỹ thuật công trình xây dựng (aun-qa)\n",
            "công nghệ kỹ thuật ô tô (aun-qa)\n",
            "công nghệ kỹ thuật cơ khí (aun-qa)\n",
            "công nghệ kỹ thuật nhiệt (aun-qa)\n",
            "quản lý công nghiệp (aun-qa)\n",
            "công nghệ kỹ thuật điều khiển và tự động hóa (aun-qa)\n",
            "công nghệ may (aun-qa)\n",
            "công nghệ kỹ thuật điện tử, truyền thông\n",
            "kỹ thuật xây dựng công trình giao thông\n",
            "công nghệ kỹ thuật máy tính\n",
            "công nghệ thông tin\n",
            "công nghệ in\n",
            "kế toán\n",
            "thương mại điện tử\n",
            "kỹ thuật công nghiệp\n",
            "kỹ thuật y sinh (điện tử y sinh)\n",
            "công nghệ vật liệu\n",
            "logistics và quản lý chuỗi cung ứng\n",
            "công nghệ kỹ thuật môi trường\n",
            "công nghệ thực phẩm\n",
            "công nghệ kỹ thuật hóa học\n",
            "kinh tế gia đình\n",
            "sư phạm tiếng anh\n",
            "ngôn ngữ anh\n",
            "kinh doanh quốc tế\n",
            "quản lý xây dựng\n",
            "năng lượng tái tạo\n",
            "chế biên lâm sản\n",
            "kỹ thuật dữ liệu\n",
            "robot và trí tuệ nhân tạo.\n",
            "bye\n",
            "BOT: Goodbye! Take care <3 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "R0cWLmQm6_Xk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}